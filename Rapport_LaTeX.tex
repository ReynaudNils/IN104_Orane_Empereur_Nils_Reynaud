%%
%% This is file `sample-sigplan.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigplan')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigplan.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigplan,screen]{acmart}
%% NOTE that a single column version is required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen,review]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{}
\copyrightyear{}
\acmYear{}
\acmDOI{}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[]{}
\acmBooktitle{}
\acmPrice{}
\acmISBN{}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}
\documentclass[12pt]{report}
%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Report IN104:Explainability in Artificial Intelligence}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Reynaud Nils}
\author{Empereur Orane}
\authornote{Both authors contributed equally to this project.}
%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
\large
The purpose of this project is to introduce machine learning and get acquainted with some methods in python langage (SHAP, LIME, PDP, CAM). Furthermore the goal is also to try to use already done works on this method and know how to readjust there to use its with other datasets. All the datatsets used in this project was found on Kaggle. The code of method presented in this project are available on kaggle with the adress : 
\small
https://github.com/ReynaudNils/IN104_Orane_Empereur_Nils_Reynaud
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}



%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.


%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
\begin{teaserfigure}
  \includegraphics[width=\textwidth]{th.jpeg}
  \caption{Titanic.}
  \Description{Titanic.}
  \label{fig:teaser}
\end{teaserfigure}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Tabular Dataset:Titanic Survivors}
\large
The data-set used for this method is the data-set of the titanic survivor. The goal is to predict the most important factors in the chance of survival.
\subsection{PDP-Partial Dependence Plots}
\large
The first method we used to understand the various machine learning models is the PDP-one, Partial Dependence Plots, which shows the marginal effect one or two features have on the predicted outcome of the model used. After exploring several PDP codes on Kaggle, there weren't many difficulties in coding.
We used it to explain two different machine learning models, xgboost and RandomForest. We'll mainly focus on the first one here.
Firstly, this method allowed us to study the importance of each feature for the model: it gives us the percentage of survivors for every value of the feature according to the real data, the percentage of survivors for every value of the feature according to the prediction of the model, and finally a partial dependance plot that shows whether the relationship between the feature we're studying and the variable target, here the survival or not of each passenger, is linear, monotonic or more complex in the prediction.
Let's first take a look at what we got for the feature Age, firstly the percentage of survivors for every age category according to the real data:
\centering
      \includegraphics[width=0.5\textwidth]{PDP_Age_1 (2).png}

Then this same percentage but according to the prediction:
\centering
      \includegraphics[width=0.5\textwidth]{2021-05-20 (6).png}
      
Finally, we get the interaction between the Age of the passenger and his survival, which is linear between 0 and 20 and then between 20 and 80.

\centering
      \includegraphics[width=0.5\textwidth]{2021-05-20 (10).png}
We did the same for other features such as Passenger class, Gender. As we can see, these interpretations are marginal, considering only one feature at a time. PDPs for two features are more relevant, as they show the interactions among the two features. We studied multiple combinations of two features, starting with Age and Passenger class: we were able to obtain the pourcentage of survivors based on these two features according to the real data.
\centering
      \includegraphics[width=0.5\textwidth]{2021-05-20 (13).png}
      
    then according to the prediction:
\centering    
      \includegraphics[width=0.5\textwidth]{2021-05-20 (12).png}
And finally the dependence of the target variable survival on joint values of Age and Passenger class
\centering
      \includegraphics[width=0.5\textwidth]{2021-05-20 (11).png}
\subsection{ICE}
Individual conditional expectation, or ICE, is a method similar to PDP but a bit improved. It also shows the dependance between the target function, here if you survived or not, and an input feature of interest. But while PDP shows the average effect of the input feature, an ICE plot visualizes the dependence of the prediction on a feature for each sample separately with one line for each sample.
We weren't able to make the code work because when entering the line: display = plot_partial_dependence(titanic_model, titanic_data, titanic_features, kind="both) the computer responded that  plot_partial_dependence() got an unexpected keyword argument 'kind'. The problem is that we need to update the version of scikit-learn to 0.24.1, however this wasn't working with the usual lines conda update conda followed by conda install scikit-learn=0.24.1.
Therefore the following graph that illustrates this method was taken online.

\subsection{SHAP}
\large
Let's now focus on the second explainability method we explored in order to understand the predictions made by the model, SHAP, or SHapley Additive ExPlanations.It is an approach based on game theory.
This time the model whose predictions we will try to understand is RandomForest.
The first plot we obtain shows the SHAP feature importance measured as the mean absolute Shapley values:
\centering
      \includegraphics[width=0.5\textwidth]{2021-05-21 (2).png}
However, this plot gives no information beyond the importance of each feature. We need a more informative plot. The next one combines feature importance with feature effect. It ranks again the features by their importance, colors show if the feature is associated with a high or low prediction, and the x-axis if the impact is positive or negative.
\centering
      \includegraphics[width=0.5\textwidth]{2021-05-20 (14).png}
Then this method gave us another plot, the SHAP dependence plot that shows the marginal effect one or two features have on the predicted outcome of our machine learning model.

\centering
      \includegraphics[width=0.5\textwidth]{2021-05-20 (15).png}).png}

The SHAP method even enables us to compare various machine learning models, RandomForest, xgb, but also MLP or LogisticRegression. It tells us the most important features for each model, which allows us to calculate a weighted SHAP Value, that takes into consideration everyone of these model. Moreover, it creates a cross-model feature importance graph. We can now objectively see the most important features.
We faced huge difficulties coding this part and weren't able to make it work, the main problem being that it took several hours for the computer to run it. 
\subsection{LIME}
\Large
LIME (Local Interpretable Model-agnostic) is a method explaining the prediction of any classifier.
The model predicts that only 0.312 percent of passenger survived, that in fact a result close of reality, so the method seem to be correct. 
\newline
    
    \centering
        \includegraphics{predictLIMEtab.png}
        
        \small result give by LIME method
        \newline

   
\Large
This paragraph will confirm that the model seem to be correct. LIME method show that the most important factor for survival is your sex, after it is the class of passenger and then the age. To obtain which features are the most important according to the model, LIME uses a slightly different input in which the data for one chosen feature are changed, and then observe the effect on the prediction outcome. In blue it is the factors which have a negative impact on the prediction and in orange a positive one. The table shows the most common values taken by the feature. For the sex 0 corresponds to a male person.
\newline
    \centering
        \includegraphics{LIMEtabresult2.png}
        \small result give by LIME method
        \newline

\Large
The image side of Out[2] was just a way to have more precise results if it is necessary.
But even if our model is optimistic it corresponds to our expectation. We compare data (different features and if passenger survived or not) of passenger thanks to graph-sticks.
    \newline
    \centering
        \includegraphics[width=0.5\textwidth]{graphclassLIMEtab.png}
        \includegraphics[width=0.5\textwidth]{graphsexLIMEtab.png}
        \small stick-graph obtained with data of titanic survivor
        \newline
        
\Large
On this graph we can see that indeed sex and class of passenger are very important factors in survival.

\subsection{Conclusion on the Tabular Dataset}
Time for a quick recap on this tabular dataset and the 4 different methods we saw to explain machine learning models. PDP is the simplest one, it shows the effect one chosen feature has on the prediction as well as the interaction between several features. ICE is the slightly more elaborate version. SHAP is much more useful, as it ranks for the given model every feature by importance, and can do so for every machine learning model. LIME offers a completely new point of view,as it shows how the prediction varies when you change the input of one the features; in other words, it describes the effect every feature has on the prediction.

\section{Text Dataset:20 NewsGroups}
\Large
We did not found text data-set about titanic survivor on Kaggle, that is why in order to test LIME method with text we chose to use another one. The data-set that we choose is 20 news groups, a famous one. The purpose is to use LIME method in order to know if the text is more a catholic opinion or a atheist one. This data-set is composed of more than 20 000 texts.

Example of result with the document number ten :
\newline
    \centering
        \includegraphics{PobaLIMEtext2.png}
        \newline
        \small result gibe LIME method
        \newline
\Larger        
There is also a graph that shows with more details the result obtained with this method (global result).
\newline
    \centering
        \includegraphics[width=0.5\textwidth]{LIMEtextglobalpredict.png}
        \small
        result LIME method, global
        \newline
\Large
With the text number ten the prediction are indicated that the higher probability is that this text is atheist (orange). In blue it is the prediction about catholic.
\newline
There is also a local explanation about why the atheist class was chosen.
\newline
    \centering
        \includegraphics[width=0.5\textwidth]{LIMEtextlocalpredict.png}
        \small
        result lime method, local
        \newline
\Larger
This graph allows us to know the words of the text that impact the AI's decision to choose the class of the text, between catholic and atheist. In that way we can start to understand the prediction we got, why we got it.

\subsection{Comparison with other method}

\Large
We tried desperately to code several other methods for this text dataset that the teacher gave us, but we weren't able to make them work. For instance we tried Pyss3, but we couldn't download it on anaconda, when coding conda install Pyss3 it could not find the package.
Therefore in this paragraph we will compare different methods completely already done and available on github at this different address :
\small
https://github.com/robinvanschaik/interpret-flair
\newline
https://github.com/cdpierse/transformers-interpret
\newline
https://github.com/UKPLab/sentence-transformers
\newline
https://github.com/sergioburdisso/pyss3
\newline
\newline
\Large
The first one, interpret-flair, uses the LayerIntegratedGradients method in order to attribute score to the world, it can be an effective way to create a summary.
The second one, transformers-interpret, uses the transformer package, it allows us to attribute a class to the word in a sentence : positive, negative or neutral. But with a larger vision it allows a support for NER models or Multiple Choice Model.
Sentence-transformers like indicate this name use Sentence-tranformers method. This method also allows to realise a summary like the first one, but it can also used in semantic research. In fact this contain lot of different methods of sentence-transformers but interpret-flair method is a better one in term of accuracy. The next figure show the results obtain by this two methods.

        \includegraphics{inter-flair.png}
        \small
        results obtain by interpret-flair method
        \newline
    \centering
        \includegraphics[width=0.5\textwidth]{trans_sentence.png}
        \small
        results obtain with different sentence-transformers methods
        \newline

\Large
The last method is a one which can be used in text classification, and have the ability to determined what it is rational. In addition, this method is very useful for model evaluation.
\newline
To conclude these four methods all treated about text data-sets (not necessary for the third and four), but there were not effective for the same application. In fact the better way to do is probably to use adapted method for each situation.



\section{Management and difficulties encounter during the project}
\subsection{Management of the project}
\Large
During the first week we tried to understand the purpose and the attempt of the project, and read documentation about the different methods in order to understand their operation. The second week we started coding with the tabular dataset. The last week we finished that and explored  kaggle for different methods for the other datasets, and finally we took the time to write this report.

\subsection{Difficulties encountered during the project}
\Large
We encountered plenty of difficulties during the project. The first one is probably about the language. Another one is that it took a lot of time to understand the goal of this project. But the hardest things it is to try to understand the method, their code, and how to adjust it in order to use in each case and different data-set. Moreover some package did not work on python even if we installed it, that is why we used notebook for LIME method (text and table).
We wish we would have been able to get going faster.However the project was complicated by the health problems of one of the author, so it took more time to understand the expectation of the course and get going. Indeed, it lead to absences which prevented us from acquainting ourselves with the tools used in IN104 (like github, Kaggle,...).

\section{To Conclude}
\Large
To conclude, this project was rather difficult but it was interesting to discover machine learning and to notice all the possibilities of application of it. It was also very interesting to learn how to use github, kaggle and to familiarize us a little bit more with Latex thanks to this report.

\end{document}
\endinput
%%
%% End of file `sample-sigplan.tex'.

